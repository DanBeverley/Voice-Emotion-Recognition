# Voice Emotion Recognition

Welcome to the Voice Emotion Recognition repository! This project aims to identify and classify emotions from speech using machine learning techniques. By analyzing various features of audio recordings, we can predict the underlying emotional state of the speaker, which has applications in fields like customer service, healthcare, and human-computer interaction. The model was train on RAVDESS , CREMA-D and SAVEE which you can find here :
https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio
https://www.kaggle.com/datasets/ejlok1/cremad
https://www.kaggle.com/datasets/ejlok1/surrey-audiovisual-expressed-emotion-savee

# Overview

This repository contains all the necessary code and resources to build a voice emotion recognition system. The project leverages deep learning models, particularly the Librosa library and recurrent neural networks (RNNs), to process audio signals and predict emotions.

# Features

+ Audio Preprocessing: Scripts for noise reduction, normalization, and feature extraction.
+ Feature Extraction: Tools to extract features such as Mel Frequency Cepstral Coefficients (MFCCs), chroma, and mel spectrograms.
+ Model Training: Implementations of CNN, RNN, and hybrid models.
+ Evaluation Metrics: Accuracy, F1-score, confusion matrix, and more.
+ Pre-trained Models: Ready-to-use models trained on popular emotion datasets.
+ Visualization: Tools to visualize training progress, model architecture, and feature importance.

+ Thank you for checking out the Voice Emotion Recognition project! If you have any questions or suggestions, feel free to open an issue or contact me directly. Happy coding!
